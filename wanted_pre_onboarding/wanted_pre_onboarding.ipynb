{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wanted_pre_onboarding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8HL2PCKwASdA9ofgOukef",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethan0625/Study_room/blob/main/wanted_pre_onboarding/wanted_pre_onboarding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 원티드 프리온보딩 사전과제(박병학)  \n",
        "## Requirement 필수 제출 사항\n",
        "\n",
        "- 원티드 이력서\n",
        "- 과제 (아래에 자세한 안내가 있습니다.)\n",
        "    - GitHub Repository 링크\n",
        "\n",
        "## 과제 안내\n",
        "\n",
        "- 아래 설명에 따라 코드의 빈칸을 채워 Tokenizer(문제 1)와 TfidfVectorizer(문제 2) 클래스를 완성하세요.\n",
        "    - 문제 1, 문제 2 모두 수행해야 합니다.\n",
        "    - 주어진 조건을 모두 만족해야 합니다.\n",
        "- 작업한 파일을 하나의 GitHub Repository에 담아서 제출하세요.\n",
        "    - 파일 형식: `.ipynb`\n",
        "        - `.ipynb` 파일 하나에 문제 1과 문제 2 작업 결과를 모두 담아 주시기 바랍니다.\n",
        "    - 링크 제출 전 해당 GitHub Repository가 public으로 설정되어 있는지 확인 바랍니다.\n",
        "        - private으로 설정 시 제출 확인이 불가합니다.  \n"
      ],
      "metadata": {
        "id": "1Ggv1skPiVV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "dRcJkEGKkHyx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **문제 1) Tokenizer 생성하기**\n",
        "\n",
        "**1-1. `preprocessing()`**\n",
        "\n",
        "텍스트 전처리를 하는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list 입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- output: 각 문장을 토큰화한 결과로, nested list 형태입니다. ex) [['i', 'go', 'to', 'school'], ['i', 'like', 'pizza']]\n",
        "- 조건 1: 입력된 문장에 대해서 소문자로의 변환과 특수문자 제거를 수행합니다.\n",
        "- 조건 2: 토큰화는 white space 단위로 수행합니다.\n",
        "    \n",
        "    \n",
        "\n",
        "**1-2. `fit()`**\n",
        "\n",
        "어휘 사전을 구축하는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list 입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- 조건 1: 위에서 만든 `preprocessing` 함수를 이용하여 각 문장에 대해 토큰화를 수행합니다.\n",
        "- 조건 2: 각각의 토큰을 정수 인덱싱 하기 위한 어휘 사전(`self.word_dict`)을 생성합니다.\n",
        "    - 주어진 코드에 있는 `self.word_dict`를 활용합니다.\n",
        "    \n",
        "\n",
        "**1-3. `transform()`**\n",
        "\n",
        "어휘 사전을 활용하여 입력 문장을 정수 인덱싱하는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- output: 각 문장의 정수 인덱싱으로, nested list 형태입니다. ex) [[1, 2, 3, 4], [1, 5, 6]]\n",
        "- 조건 1: 어휘 사전(`self.word_dict`)에 없는 단어는 'oov'의 index로 변환합니다."
      ],
      "metadata": {
        "id": "ZWHBt26Gityh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w0G5HDWZg7LO"
      },
      "outputs": [],
      "source": [
        "class Tokenizer():\n",
        "    def __init__(self):\n",
        "        self.word_dict = {'oov': 0}\n",
        "        self.fit_checker = False\n",
        "\n",
        "    def preprocessing(self, sequences):\n",
        "        self.sequences = sequences\n",
        "        result = []\n",
        "        '''\n",
        "        문제 1-1.\n",
        "        '''\n",
        "        # 반복문을 통한 전처리 구간\n",
        "        for sen in sequences:\n",
        "            # 대문자를 소문자로 일괄변경\n",
        "            temp = sen.lower()\n",
        "            # 정규식을 활용, 특수문자 제거\n",
        "            temp = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','', temp)\n",
        "            # white space를 기준으로 문장 토큰화\n",
        "            temp = temp.split()\n",
        "            # list로 받은 토큰들을 result에 append\n",
        "            result.append(temp)\n",
        "\n",
        "        return result\n",
        "  \n",
        "    def fit(self, sequences):\n",
        "        self.fit_checker = False\n",
        "        '''\n",
        "        문제 1-2.\n",
        "        '''\n",
        "        # tokens변수를 활용하여 전처리 결과를 저장\n",
        "        tokens = self.preprocessing(sequences)\n",
        "        # 정수 번호를 지정해주기 위해서 len()활용\n",
        "        num = len(self.word_dict)\n",
        "        # 문장에서 토큰을 하나씩 뽑기 위해 이중 for문 활용\n",
        "        for word in tokens:\n",
        "            for i in word:\n",
        "                # wrod_dict에 해당 단어가 들어있지 않으면 새로운 단어로 판단하여\n",
        "                # word_dict에 num을 할당하여 추가\n",
        "                if i not in self.word_dict:\n",
        "                    self.word_dict[i] = num\n",
        "                    # 다음 단어는 다음 정수를 받아야 하므로\n",
        "                    # 새로운 단어가 추가 되었을 때 num+=1을 통해 정수 1 증가\n",
        "                    num+=1\n",
        "\n",
        "        self.fit_checker = True\n",
        "  \n",
        "    def transform(self, sequences):\n",
        "        result = []\n",
        "        tokens = self.preprocessing(sequences)\n",
        "        if self.fit_checker:\n",
        "            '''\n",
        "            문제 1-3.\n",
        "            '''\n",
        "            for word in tokens:\n",
        "                word2idx = []\n",
        "                for i in word:\n",
        "                    if i in self.word_dict:\n",
        "                        word2idx.append(self.word_dict[i])\n",
        "                    else :\n",
        "                        word2idx.append(self.word_dict['oov'])\n",
        "                result.append(word2idx)\n",
        "            return result\n",
        "        else:\n",
        "            raise Exception(\"Tokenizer instance is not fitted yet.\")\n",
        "      \n",
        "    def fit_transform(self, sequences):\n",
        "        self.fit(sequences)\n",
        "        result = self.transform(sequences)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **문제 2) TfidfVectorizer 생성하기**\n",
        "\n",
        "**2-1. `fit()`**\n",
        "\n",
        "입력 문장들을 이용해 IDF 행렬을 만드는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list 입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- 조건 1: IDF 행렬은 list 형태입니다.\n",
        "    - ex) [토큰1에 대한 IDF 값, 토큰2에 대한 IDF 값, .... ]\n",
        "- 조건 2: IDF 값은 아래 식을 이용해 구합니다.\n",
        "    \n",
        "    $$\n",
        "    idf(d,t)=log_e(\\frac{n}{1+df(d,t)})\n",
        "    $$\n",
        "    \n",
        "    - $df(d,t)$ : 단어 t가 포함된 문장 d의 개수\n",
        "    - $n$ : 입력된 전체 문장 개수\n",
        "- 조건 3: 입력된 문장의 토큰화에는 문제 1에서 만든 Tokenizer를 사용합니다.\n",
        "    \n",
        "    \n",
        "\n",
        "**2-2. `transform()`**\n",
        "\n",
        "입력 문장들을 이용해 TF-IDF 행렬을 만드는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- output : nested list 형태입니다.\n",
        "    \n",
        "    ex) [[tf-idf(1, 1), tf-idf(1, 2), tf-idf(1, 3)], [tf-idf(2, 1), tf-idf(2, 2), tf-idf(2, 3)]]\n",
        "\n",
        "|  | 토큰1 | 토큰2 | 토큰3 |\n",
        "| --- | --- | --- | --- |\n",
        "| 문장1 | tf-idf(1,1) | tf-idf(1,2) | tf-idf(1,3) |\n",
        "| 문장2 | tf-idf(2,1) | tf-idf(2,2) | tf-idf(2,3) |\n",
        "\n",
        "- 조건1 : 입력 문장을 이용해 TF 행렬을 만드세요.\n",
        "    - $tf(d, t)$ : 문장 d에 단어 t가 나타난 횟수\n",
        "- 조건2 : 문제 2-1( `fit()`)에서 만든 IDF 행렬과 아래 식을 이용해 TF-IDF 행렬을 만드세요\n",
        "    \n",
        "$$\n",
        "tf-idf(d,t) = tf(d,t) \\times idf(d,t)\n",
        "$$"
      ],
      "metadata": {
        "id": "AEvQf9WFRJJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sen = ['I go to school.', 'I LIKE pizza!']\n",
        "tok = Tokenizer()\n",
        "res = tok.fit_transform(sen)"
      ],
      "metadata": {
        "id": "bt0jVcp5ZUdd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_ZLSvuPZb4V",
        "outputId": "8efa3b3c-be65-40b6-a17c-397d5084d224"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4], [1, 5, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "from collections import Counter, defaultdict"
      ],
      "metadata": {
        "id": "ZAWJWktEf9Ye"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TfidfVectorizer:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.fit_checker = False\n",
        "        self.idf_matrix = []\n",
        "        self.tfidf_matrix = []\n",
        "        self.count = Counter()\n",
        "        self.idf_dict = defaultdict()\n",
        "\n",
        "    def fit(self, sequences):\n",
        "        tokenized = self.tokenizer.fit_transform(sequences)\n",
        "        '''\n",
        "        문제 2-1.\n",
        "        '''\n",
        "        n = len(tokenized)\n",
        "        for i in tokenized:\n",
        "            self.count += Counter(i)\n",
        "\n",
        "        for k, v in self.count.items():\n",
        "            self.idf_matrix.append(log(n/1+v))\n",
        "            self.idf_dict[k] = log(n/1+v)\n",
        "\n",
        "        self.fit_checker = True\n",
        "\n",
        "\n",
        "    def transform(self, sequences):\n",
        "        if self.fit_checker:\n",
        "            tokenized = self.tokenizer.transform(sequences)\n",
        "            '''\n",
        "            문제 2-2.\n",
        "            '''\n",
        "            def _tf_idf(sen):\n",
        "                tmp = []\n",
        "                for i in self.idf_dict.keys():\n",
        "                    tf_idf = sen.count(i)*self.idf_dict[i]\n",
        "                    tmp.append(tf_idf)\n",
        "                return tmp\n",
        "\n",
        "            for i in tokenized:\n",
        "                self.tfidf_matrix.append(_tf_idf(i))\n",
        "\n",
        "            return self.tfidf_matrix\n",
        "        else:\n",
        "            raise Exception(\"TfidfVectorizer instance is not fitted yet.\")\n",
        "\n",
        "\n",
        "    def fit_transform(self, sequences):\n",
        "        self.fit(sequences)\n",
        "        return self.transform(sequences)"
      ],
      "metadata": {
        "id": "YCdLbKNBV7Ql"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tok.transform(sen)"
      ],
      "metadata": {
        "id": "hBsLt8Gv5JdB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(tok)"
      ],
      "metadata": {
        "id": "i9O9MG6ygqVH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = tfidf.fit_transform(sen)"
      ],
      "metadata": {
        "id": "PHCV8yXR7oim"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I10AH1dV7tdj",
        "outputId": "87388222-3474-4560-f724-96dc5e656865"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.3862943611198906,\n",
              "  1.0986122886681098,\n",
              "  1.0986122886681098,\n",
              "  1.0986122886681098,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [1.3862943611198906, 0.0, 0.0, 0.0, 1.0986122886681098, 1.0986122886681098]]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf_matrix = tfidf.fit(sen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXXIoTLngwnm",
        "outputId": "6730d687-763d-40f5-9b25-89ca49a42ad8"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count : Counter({1: 2, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1})\n",
            "0\n",
            "sen : [1, 2, 3, 4]\n",
            "df : 0\n",
            "sen : [1, 5, 6]\n",
            "df : 0\n",
            "1\n",
            "sen : [1, 2, 3, 4]\n",
            "df : 1\n",
            "sen : [1, 5, 6]\n",
            "df : 2\n",
            "2\n",
            "sen : [1, 2, 3, 4]\n",
            "df : 1\n",
            "sen : [1, 5, 6]\n",
            "df : 1\n",
            "3\n",
            "sen : [1, 2, 3, 4]\n",
            "df : 1\n",
            "sen : [1, 5, 6]\n",
            "df : 1\n",
            "4\n",
            "sen : [1, 2, 3, 4]\n",
            "df : 1\n",
            "sen : [1, 5, 6]\n",
            "df : 1\n",
            "5\n",
            "sen : [1, 2, 3, 4]\n",
            "df : 0\n",
            "sen : [1, 5, 6]\n",
            "df : 1\n",
            "6\n",
            "sen : [1, 2, 3, 4]\n",
            "df : 0\n",
            "sen : [1, 5, 6]\n",
            "df : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf_matrix"
      ],
      "metadata": {
        "id": "xP8lfI7YhdPu"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chk = tfidf.fit_transform(sen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ZU2N6Pwv5h",
        "outputId": "3d031fad-b0e3-4898-b59d-39e9727ed8f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "['I go to school.', 'I LIKE pizza!']\n",
            "[[1, 2, 3, 4], [1, 5, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[1.3862943611198906,\n",
        " 1.0986122886681098,\n",
        " 1.0986122886681098,\n",
        " 1.0986122886681098,\n",
        " 1.0986122886681098,\n",
        " 1.0986122886681098]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMIrCaMCsDnp",
        "outputId": "e7de918b-34c9-46f3-945e-6d6d29300d0a"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3862943611198906,\n",
              " 1.0986122886681098,\n",
              " 1.0986122886681098,\n",
              " 1.0986122886681098,\n",
              " 1.0986122886681098,\n",
              " 1.0986122886681098]"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # 데이터프레임 사용을 위해\n",
        "from math import log # IDF 계산을 위해\n",
        "\n",
        "docs = ['i go to school', 'i like pizza']\n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()\n",
        "\n",
        "# 총 문서의 수\n",
        "N = len(docs) \n",
        "\n",
        "def tf(t, d):\n",
        "  return d.count(t)\n",
        "\n",
        "def idf(t):\n",
        "  df = 0\n",
        "  for doc in docs:\n",
        "    df += t in doc\n",
        "  return log((N)/(df+1))\n",
        "\n",
        "def tfidf(t, d):\n",
        "  return tf(t,d)* idf(t)\n",
        "\n",
        "\n",
        "result = []\n",
        "for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "    result.append(idf(t))\n",
        "\n",
        "idf_ = pd.DataFrame(result, index=vocab, columns=[\"IDF\"])\n",
        "idf_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "3MkvOcUojRyA",
        "outputId": "6813b471-0cec-4625-8e11-cbb3818cf796"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f420d679-f132-45f9-8a67-2099977e8da3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>go</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i</th>\n",
              "      <td>-0.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pizza</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>school</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f420d679-f132-45f9-8a67-2099977e8da3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f420d679-f132-45f9-8a67-2099977e8da3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f420d679-f132-45f9-8a67-2099977e8da3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             IDF\n",
              "go      0.000000\n",
              "i      -0.405465\n",
              "like    0.000000\n",
              "pizza   0.000000\n",
              "school  0.000000\n",
              "to      0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "corpus = ['i go to school', 'i like pizza']\n",
        "\n",
        "vect = CountVectorizer()\n",
        "document_term_matrix = vect.fit_transform(corpus)       # 문서-단어 행렬 \n",
        "\n",
        "tf = pd.DataFrame(document_term_matrix.toarray(), columns=vect.get_feature_names())  \n",
        "                                             # TF (Term Frequency)\n",
        "D = len(tf)\n",
        "df = tf.astype(bool).sum(axis=0)\n",
        "idf = np.log((D+1) / (df+1)) + 1             # IDF (Inverse Document Frequency)\n",
        "\n",
        "# TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "tfidf = tf * idf                      \n",
        "tfidf = tfidf / np.linalg.norm(tfidf, axis=1, keepdims=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbBL5XjyiM6b",
        "outputId": "ef0f255d-cc00-4d92-a0f1-5adaf15856f8"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_GNoj2XpGEB",
        "outputId": "c227e61a-df70-46ed-e004-773b6005efa9"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "go        1.405465\n",
              "like      1.405465\n",
              "pizza     1.405465\n",
              "school    1.405465\n",
              "to        1.405465\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_vectorizer.fit(text_data)\n",
        "print(tfidf_vectorizer.vocabulary_)\n",
        "\n",
        "sentence = [text_data[3]] #['점심 먹고 공부 해야지']\n",
        "print(tfidf_vectorizer.transform(text_data).toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8dQ-tXtpH26",
        "outputId": "8dae45b6-43d2-4adb-a918-62c521c74920"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n",
            "[[0.57735027 0.         0.57735027 0.         0.         0.\n",
            "  0.57735027 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.52640543 0.         0.66767854\n",
            "  0.         0.52640543 0.         0.        ]\n",
            " [0.         0.52640543 0.         0.52640543 0.         0.\n",
            "  0.         0.         0.66767854 0.        ]\n",
            " [0.         0.43779123 0.         0.         0.55528266 0.\n",
            "  0.         0.43779123 0.         0.55528266]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "S3zOAgEYp4j9"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = Counter()\n",
        "for i in res:\n",
        "    print(Counter(i))\n",
        "    tmp += Counter(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWtq0Uf3qKvk",
        "outputId": "73d9def3-9662-44ef-fd97-37f020f13752"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 1, 2: 1, 3: 1, 4: 1})\n",
            "Counter({1: 1, 5: 1, 6: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NYuykTGqUfQ",
        "outputId": "be1770c2-9f72-4f39-d61c-d3df23a0166b"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 2, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1})"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1n9uoitJtdmC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}